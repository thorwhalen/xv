{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arxiv Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xv import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the point of writing this, my attempts enable `graze` to automatically confirm download in the googledrive downloads (which, when downloading too-big files, will tell the user it can't scan the file and ask the user to confirm the download).\n",
    "\n",
    "Therefore, the following files need to be downloaded manually:\n",
    "* **titles**: https://drive.google.com/file/d/1Ul5mPePtoPKHZkH5Rm6dWKAO11dG98GN/view?usp=share_link\n",
    "* **abstracts**: https://drive.google.com/file/d/1g3K-wlixFxklTSUQNZKpEgN4WNTFTPIZ/view?usp=share_link\n",
    "\n",
    "(If those urls don't work, perhaps they were updated: See here: https://alex.macrocosm.so/download .)\n",
    "\n",
    "You can then copy them over to the place graze will look for by doing:\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "from xv.util import Graze\n",
    "from xv.data_access import urls\n",
    "\n",
    "\n",
    "g[urls['titles']] = Path('TITLES_DATA_LOCAL_FILEPATH').read_bytes()\n",
    "g[urls['abstracts']] = Path('ABSTRACTS_DATA_LOCAL_FILEPATH').read_bytes()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imbed.mdat.arxiv import urls\n",
    "# from pathlib import Path\n",
    "\n",
    "# g[urls['titles']] = Path('FILE_WHERE_YOU_DOWNLOADED_TITLES_DATA').read_bytes()\n",
    "# g[urls['abstracts']] = Path('FILE_WHERE_YOU_DOWNLOADED_TITLES_DATA').read_bytes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://drive.google.com/file/d/1Ul5mPePtoPKHZkH5Rm6dWKAO11dG98GN/view?usp=share_link',\n",
       " 'https://drive.google.com/file/d/1g3K-wlixFxklTSUQNZKpEgN4WNTFTPIZ/view?usp=share_link',\n",
       " 'https://arxiv.org/pdf/0704.0001']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xv.util import Graze\n",
    "\n",
    "g = Graze()\n",
    "list(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['titles', 'abstracts']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xv import raw_sources\n",
    "\n",
    "list(raw_sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['titles_7.parquet',\n",
       " 'titles_23.parquet',\n",
       " 'titles_15.parquet',\n",
       " 'verifyResults.py',\n",
       " 'titles_14.parquet',\n",
       " 'titles_22.parquet',\n",
       " 'titles_6.parquet',\n",
       " 'titles_16.parquet',\n",
       " 'titles_20.parquet',\n",
       " 'titles_4.parquet',\n",
       " 'titles_5.parquet',\n",
       " 'titles_21.parquet',\n",
       " 'params.txt',\n",
       " 'titles_17.parquet',\n",
       " 'exampleEmbed.py',\n",
       " 'titles_12.parquet',\n",
       " 'README.md',\n",
       " 'titles_9.parquet',\n",
       " 'titles_1.parquet',\n",
       " 'titles_13.parquet',\n",
       " 'titles_8.parquet',\n",
       " 'titles_18.parquet',\n",
       " 'titles_3.parquet',\n",
       " 'titles_11.parquet',\n",
       " 'titles_10.parquet',\n",
       " 'titles_19.parquet',\n",
       " 'titles_2.parquet']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = raw_sources['titles']\n",
    "list(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from InstructorEmbedding import INSTRUCTOR\n",
      "\n",
      "model = INSTRUCTOR('hkunlp/instructor-xl')\n",
      "sentence = \"3D ActionSLAM: wearable person tracking in multi-floor environments\"\n",
      "instruction = \"Represent the Research Paper title for retrieval; Input:\"\n",
      "embeddings = model.encode([[instruction,sentence]])\n",
      "print(embeddings)\n"
     ]
    }
   ],
   "source": [
    "print(raw['exampleEmbed.py'].decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thorwhalen/.pyenv/versions/3.10.13/envs/p10/lib/python3.10/site-packages/InstructorEmbedding/instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from InstructorEmbedding import INSTRUCTOR\n",
    "\n",
    "model = INSTRUCTOR('hkunlp/instructor-xl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"3D ActionSLAM: wearable person tracking in multi-floor environments\"\n",
    "instruction = \"Represent the Research Paper title for retrieval; Input:\"\n",
    "embeddings = model.encode([[instruction, sentence]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: Represent the Research Paper title for retrieval; Input:\n",
      "type: title\n",
      "time string: 20230518-185428\n",
      "model: InstructorXL\n",
      "version: 2.0\n"
     ]
    }
   ],
   "source": [
    "print(raw['params.txt'].decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from InstructorEmbedding import INSTRUCTOR\n",
      "\n",
      "model = INSTRUCTOR('hkunlp/instructor-xl')\n",
      "sentence = \"3D ActionSLAM: wearable person tracking in multi-floor environments\"\n",
      "instruction = \"Represent the Research Paper title for retrieval; Input:\"\n",
      "embeddings = model.encode([[instruction,sentence]])\n",
      "print(embeddings)\n"
     ]
    }
   ],
   "source": [
    "print(raw['exampleEmbed.py'].decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The imbedding data store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we'll transform the raw store to get a convenient interface to the actual data of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313383694"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = raw['titles_1.parquet']\n",
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n"
     ]
    }
   ],
   "source": [
    "from xv import sources  # raw store + wrapper. See parquet_codec code.\n",
    "\n",
    "titles_tables = sources['titles']\n",
    "abstract_tables = sources['abstracts']\n",
    "print(list(titles_tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>[-0.050620172, 0.041436385, 0.05363288, -0.029...</td>\n",
       "      <td>0704.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>[0.014515653, 0.023809524, -0.028145121, -0.04...</td>\n",
       "      <td>0704.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The evolution of the Earth-Moon system based o...</td>\n",
       "      <td>[-4.766115e-05, 0.017415706, 0.04146007, -0.03...</td>\n",
       "      <td>0704.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
       "      <td>[0.027208889, 0.046175897, 0.0010913888, -0.01...</td>\n",
       "      <td>0704.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n",
       "      <td>[0.0113909235, 0.0042667952, -0.0008565594, -0...</td>\n",
       "      <td>0704.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Multiple Time Dimensions</td>\n",
       "      <td>[0.02682626, -0.0015173098, -0.0019915192, -0....</td>\n",
       "      <td>0812.3869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Depth Zero Representations of Nonlinear Covers...</td>\n",
       "      <td>[-0.02740943, 0.011689809, -0.0105154915, -0.0...</td>\n",
       "      <td>0812.3870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Decting Errors in Reversible Circuits With Inv...</td>\n",
       "      <td>[0.0072460608, 0.0028085636, -0.015064359, -0....</td>\n",
       "      <td>0812.3871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Unveiling the birth and evolution of the HII r...</td>\n",
       "      <td>[0.009408689, -0.0047120117, 0.0021392817, -0....</td>\n",
       "      <td>0812.3872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>The K-Receiver Broadcast Channel with Confiden...</td>\n",
       "      <td>[-0.0026305509, -0.006502139, 0.013400236, -0....</td>\n",
       "      <td>0812.3873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      Calculation of prompt diphoton production cros...   \n",
       "1               Sparsity-certifying Graph Decompositions   \n",
       "2      The evolution of the Earth-Moon system based o...   \n",
       "3      A determinant of Stirling cycle numbers counts...   \n",
       "4      From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
       "...                                                  ...   \n",
       "99995                           Multiple Time Dimensions   \n",
       "99996  Depth Zero Representations of Nonlinear Covers...   \n",
       "99997  Decting Errors in Reversible Circuits With Inv...   \n",
       "99998  Unveiling the birth and evolution of the HII r...   \n",
       "99999  The K-Receiver Broadcast Channel with Confiden...   \n",
       "\n",
       "                                              embeddings        doi  \n",
       "0      [-0.050620172, 0.041436385, 0.05363288, -0.029...  0704.0001  \n",
       "1      [0.014515653, 0.023809524, -0.028145121, -0.04...  0704.0002  \n",
       "2      [-4.766115e-05, 0.017415706, 0.04146007, -0.03...  0704.0003  \n",
       "3      [0.027208889, 0.046175897, 0.0010913888, -0.01...  0704.0004  \n",
       "4      [0.0113909235, 0.0042667952, -0.0008565594, -0...  0704.0005  \n",
       "...                                                  ...        ...  \n",
       "99995  [0.02682626, -0.0015173098, -0.0019915192, -0....  0812.3869  \n",
       "99996  [-0.02740943, 0.011689809, -0.0105154915, -0.0...  0812.3870  \n",
       "99997  [0.0072460608, 0.0028085636, -0.015064359, -0....  0812.3871  \n",
       "99998  [0.009408689, -0.0047120117, 0.0021392817, -0....  0812.3872  \n",
       "99999  [-0.0026305509, -0.006502139, 0.013400236, -0....  0812.3873  \n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_df = titles_tables[1]\n",
    "titles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>[-0.035151865, 0.022851437, 0.025942933, -0.02...</td>\n",
       "      <td>0704.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>[0.035485767, -0.0015772493, -0.0016615744, -0...</td>\n",
       "      <td>0704.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The evolution of Earth-Moon system is descri...</td>\n",
       "      <td>[-0.014510429, 0.010210799, 0.049661566, -0.01...</td>\n",
       "      <td>0704.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We show that a determinant of Stirling cycle...</td>\n",
       "      <td>[0.029191103, 0.047992915, -0.0061754594, -0.0...</td>\n",
       "      <td>0704.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In this paper we show how to compute the $\\L...</td>\n",
       "      <td>[-0.015174898, 0.01603887, 0.04062805, -0.0246...</td>\n",
       "      <td>0704.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>The possibility of physics in multiple time ...</td>\n",
       "      <td>[0.016121766, 0.011126887, 0.018650021, -0.044...</td>\n",
       "      <td>0812.3869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>We generalize the methods of Moy-Prasad, in ...</td>\n",
       "      <td>[-7.164341e-05, -0.007114291, -0.008979887, -0...</td>\n",
       "      <td>0812.3870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Reversible logic is experience renewed inter...</td>\n",
       "      <td>[0.03194286, -0.00771745, 0.015977046, -0.0474...</td>\n",
       "      <td>0812.3871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Based on a multiwavelength study, the ISM ar...</td>\n",
       "      <td>[-0.012340169, -0.021712925, 0.00806009, -0.00...</td>\n",
       "      <td>0812.3872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>The secrecy capacity region for the K-receiv...</td>\n",
       "      <td>[0.0012416588, 0.0006933478, -0.0057888636, -0...</td>\n",
       "      <td>0812.3873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                abstract  \\\n",
       "0        A fully differential calculation in perturba...   \n",
       "1        We describe a new algorithm, the $(k,\\ell)$-...   \n",
       "2        The evolution of Earth-Moon system is descri...   \n",
       "3        We show that a determinant of Stirling cycle...   \n",
       "4        In this paper we show how to compute the $\\L...   \n",
       "...                                                  ...   \n",
       "99995    The possibility of physics in multiple time ...   \n",
       "99996    We generalize the methods of Moy-Prasad, in ...   \n",
       "99997    Reversible logic is experience renewed inter...   \n",
       "99998    Based on a multiwavelength study, the ISM ar...   \n",
       "99999    The secrecy capacity region for the K-receiv...   \n",
       "\n",
       "                                              embeddings        doi  \n",
       "0      [-0.035151865, 0.022851437, 0.025942933, -0.02...  0704.0001  \n",
       "1      [0.035485767, -0.0015772493, -0.0016615744, -0...  0704.0002  \n",
       "2      [-0.014510429, 0.010210799, 0.049661566, -0.01...  0704.0003  \n",
       "3      [0.029191103, 0.047992915, -0.0061754594, -0.0...  0704.0004  \n",
       "4      [-0.015174898, 0.01603887, 0.04062805, -0.0246...  0704.0005  \n",
       "...                                                  ...        ...  \n",
       "99995  [0.016121766, 0.011126887, 0.018650021, -0.044...  0812.3869  \n",
       "99996  [-7.164341e-05, -0.007114291, -0.008979887, -0...  0812.3870  \n",
       "99997  [0.03194286, -0.00771745, 0.015977046, -0.0474...  0812.3871  \n",
       "99998  [-0.012340169, -0.021712925, 0.00806009, -0.00...  0812.3872  \n",
       "99999  [0.0012416588, 0.0006933478, -0.0057888636, -0...  0812.3873  \n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_df = abstract_tables[1]\n",
    "abstract_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0704.0001', '0704.0002', '0704.0003', ..., '0812.3871',\n",
       "       '0812.3872', '0812.3873'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_df['doi'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://arxiv.org/abs/0704.0001'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xv import arxiv_url\n",
    "\n",
    "doi = abstract_df['doi'].values[0]\n",
    "arxiv_url(doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abs': 'Main page of article. Contains links to all other relevant information.',\n",
       " 'pdf': 'Direct link to article pdf',\n",
       " 'format': 'Page giving access to other formats',\n",
       " 'src': 'Access to the original source files submitted by the authors.',\n",
       " 'cits': 'Tracks citations of the article across various platforms and databases.',\n",
       " 'html': 'Link to the ar5iv html page for the article.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xv.data_access import resource_descriptions\n",
    "resource_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs: Main page of article. Contains links to all other relevant information.\n",
      "Example: https://arxiv.org/abs/0704.0001\n",
      "\n",
      "pdf: Direct link to article pdf\n",
      "Example: https://arxiv.org/pdf/0704.0001\n",
      "\n",
      "format: Page giving access to other formats\n",
      "Example: https://arxiv.org/format/0704.0001\n",
      "\n",
      "src: Access to the original source files submitted by the authors.\n",
      "Example: https://arxiv.org/src/0704.0001\n",
      "\n",
      "cits: Tracks citations of the article across various platforms and databases.\n",
      "Example: https://arxiv.org/cits/0704.0001\n",
      "\n",
      "html: Link to the ar5iv html page for the article.\n",
      "Example: https://ar5iv.labs.arxiv.org/html/0704.0001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doi = '0704.0001'\n",
    "\n",
    "for resource, description in resource_descriptions.items():\n",
    "    print(f\"{resource}: {description}\")\n",
    "    print(f\"Example: {arxiv_url(doi, resource)}\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://arxiv.org/pdf/0704.0001'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_url(doi, 'pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The contents  (~1.647MB) of https://arxiv.org/pdf/0704.0001 are being downloaded...\n"
     ]
    }
   ],
   "source": [
    "pdf_bytes = g[arxiv_url(doi, 'pdf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_df.embeddings.values[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umap 2d embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note: For `ColumnOrientedMapping` see [Column-oriented DBMS](https://en.wikipedia.org/wiki/Column-oriented_DBMS). It's overkill here, but wanted to try it out.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, json, os\n",
    "from dol import PickleFiles, JsonFiles  # TODO: make PickleFiles work\n",
    "from py2store import PickleStore\n",
    "\n",
    "pkl_store = PickleStore(os.path.expanduser('~/tmp/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make and save umap embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kind = 'titles'  # 'titles' or 'abstracts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title', 'embeddings', 'doi']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xv import sources \n",
    "from tabled import ColumnOrientedMapping\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "tables = sources[kind]\n",
    "tables_merge = ColumnOrientedMapping(tables)\n",
    "list(tables_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: In the following, we lighten up heavy variables as soon as we're finished with them.\n",
    "# Doing this because got a lot of \"kernel died\" errors, and I'm guessing it's because of memory issues.\n",
    "# Note: Perhaps running this in as a python script (rather than in a notebook) would help too.\n",
    "\n",
    "embeddings_array = np.vstack(tables_merge['embeddings'])\n",
    "print(f\"{embeddings_array.shape=}\")\n",
    "del tables_merge\n",
    "del tables\n",
    "\n",
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "planar_embedding = reducer.fit_transform(embeddings_array)\n",
    "del reducer\n",
    "print(f\"{planar_embedding.shape=}\")\n",
    "\n",
    "pkl_store[f'arxiv-{kind}-2d-embedding.pkl'] = planar_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make csvs with umap embeddings and info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.expanduser('~/tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2store import PickleStore\n",
    "import os\n",
    "\n",
    "def tables_without_embeddings(tables):\n",
    "    for d in tables.values():\n",
    "        del d['embeddings']\n",
    "        yield d\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# for kind in ['titles']:\n",
    "for kind in ['abstracts']:\n",
    "# for kind in ['titles', 'abstracts']:\n",
    "    tables = sources[kind]\n",
    "    df = pd.concat(tables_without_embeddings(tables), axis=0)\n",
    "    df['id'] = range(len(df)) # an id column is needed for cosmograph\n",
    "\n",
    "    p = PickleStore(os.path.expanduser('~/tmp/'))\n",
    "    planar_embedding = p[f'arxiv-{kind}-2d-embedding.pkl']\n",
    "\n",
    "    df['x'] = planar_embedding[:, 0]\n",
    "    df['y'] = planar_embedding[:, 1]\n",
    "\n",
    "    save_filepath = os.path.join(save_dir, f'arxiv-{kind}-2d-embedding.csv')\n",
    "    df.to_csv(save_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s0/6rhqzsnx0lxbjs8r5rhld9km0000gn/T/ipykernel_2790/1949567189.py:3: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  a = pd.read_csv(os.path.join(save_dir, f'arxiv-abstracts-2d-embedding.csv'), index_col=0)\n",
      "/var/folders/s0/6rhqzsnx0lxbjs8r5rhld9km0000gn/T/ipykernel_2790/1949567189.py:4: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  t = pd.read_csv(os.path.join(save_dir, f'arxiv-titles-2d-embedding.csv'), index_col=0)\n"
     ]
    }
   ],
   "source": [
    "# abstracts embedding, with titles columns, but not abstracts (too heavy!!)\n",
    "\n",
    "a = pd.read_csv(os.path.join(save_dir, f'arxiv-abstracts-2d-embedding.csv'), index_col=0)\n",
    "t = pd.read_csv(os.path.join(save_dir, f'arxiv-titles-2d-embedding.csv'), index_col=0)\n",
    "\n",
    "df = a.merge(t[['doi', 'title']], how='inner', on='doi')\n",
    "del df['abstract']\n",
    "save_filepath = os.path.join(save_dir, f'arxiv-abstracts-2d-embedding-without-abstracts.csv')\n",
    "df.to_csv(save_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s0/6rhqzsnx0lxbjs8r5rhld9km0000gn/T/ipykernel_2790/2317137206.py:6: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the csv into two parts\n",
    "\n",
    "data_path = os.path.join(save_dir, f'arxiv-abstracts-2d-embedding-without-abstracts.csv')\n",
    "midpoint = 1_000_000\n",
    "\n",
    "df = pd.read_csv(data_path, index_col=0)\n",
    "df_part = df.iloc[:1_000_000]\n",
    "df_part.to_csv(data_path.replace('.csv', f'<{midpoint}.csv'))\n",
    "df_part = df.iloc[1_000_000:]\n",
    "df_part.to_csv(data_path.replace('.csv', f'>{midpoint}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s0/6rhqzsnx0lxbjs8r5rhld9km0000gn/T/ipykernel_2790/2239995952.py:3: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  a = pd.read_csv(os.path.join(save_dir, f'arxiv-abstracts-2d-embedding.csv'), index_col=0)\n",
      "/var/folders/s0/6rhqzsnx0lxbjs8r5rhld9km0000gn/T/ipykernel_2790/2239995952.py:4: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  t = pd.read_csv(os.path.join(save_dir, f'arxiv-titles-2d-embedding.csv'), index_col=0)\n"
     ]
    }
   ],
   "source": [
    "# More (BIG ONES!!) \n",
    "\n",
    "a = pd.read_csv(os.path.join(save_dir, f'arxiv-abstracts-2d-embedding.csv'), index_col=0)\n",
    "t = pd.read_csv(os.path.join(save_dir, f'arxiv-titles-2d-embedding.csv'), index_col=0)\n",
    "\n",
    "# title embeddings, with abstract field\n",
    "df = t.merge(a[['doi', 'abstract']], how='inner', on='doi')\n",
    "t_save_filepath = os.path.join(save_dir, f'arxiv-titles-2d-embedding-with-abstracts.csv')\n",
    "df.to_csv(t_save_filepath)\n",
    "\n",
    "# abstract embeddings, with title field\n",
    "df = a.merge(t[['doi', 'title']], how='inner', on='doi')\n",
    "a_save_filepath = os.path.join(save_dir, f'arxiv-abstracts-2d-embedding-with-titles.csv')\n",
    "df.to_csv(a_save_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"
     ]
    }
   ],
   "source": [
    "from imbed.mdat.arxiv import sources\n",
    "\n",
    "tables = sources['abstracts']\n",
    "print(*tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = next(iter(tables.values()))\n",
    "\n",
    "from langchain.schema import Document\n",
    "from itertools import repeat\n",
    "# make a langchain docs iterable\n",
    "\n",
    "\n",
    "class LangchainDocs:\n",
    "    def __init__(self, texts, metadatas=None):\n",
    "        self.texts = texts\n",
    "        self.metadatas = metadatas #or repeat({})  # same dict for all: TODO: change\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.metadatas is None:\n",
    "            return (Document(page_content=text) for text in self.texts)\n",
    "        else:\n",
    "            return (\n",
    "                Document(page_content=text, metadata=meta) \n",
    "                for text, meta in zip(self.texts, self.metadatas)\n",
    "            )\n",
    "        \n",
    "\n",
    "docs = LangchainDocs(\n",
    "    table['abstract'].values, \n",
    "    ({'doi': doi} for doi in table['doi'].iloc[:1000].values)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(docs, embeddings)\n",
    "# 1m02 for 10000 docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method from_documents in module langchain_community.vectorstores.chroma:\n",
      "\n",
      "from_documents(documents: 'List[Document]', embedding: 'Optional[Embeddings]' = None, ids: 'Optional[List[str]]' = None, collection_name: 'str' = 'langchain', persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, client: 'Optional[chromadb.Client]' = None, collection_metadata: 'Optional[Dict]' = None, **kwargs: 'Any') -> 'Chroma' method of abc.ABCMeta instance\n",
      "    Create a Chroma vectorstore from a list of documents.\n",
      "    \n",
      "    If a persist_directory is specified, the collection will be persisted there.\n",
      "    Otherwise, the data will be ephemeral in-memory.\n",
      "    \n",
      "    Args:\n",
      "        collection_name (str): Name of the collection to create.\n",
      "        persist_directory (Optional[str]): Directory to persist the collection.\n",
      "        ids (Optional[List[str]]): List of document IDs. Defaults to None.\n",
      "        documents (List[Document]): List of documents to add to the vectorstore.\n",
      "        embedding (Optional[Embeddings]): Embedding function. Defaults to None.\n",
      "        client_settings (Optional[chromadb.config.Settings]): Chroma client settings\n",
      "        collection_metadata (Optional[Dict]): Collection configurations.\n",
      "                                              Defaults to None.\n",
      "    \n",
      "    Returns:\n",
      "        Chroma: Chroma vectorstore.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Chroma.from_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = vectorstore.similarity_search('similarity search')\n",
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='  Modern text retrieval systems often provide a similarity search utility, that\\nallows the user to find efficiently a fixed number k of documents in the data\\nset that are most similar to a given query (here a query is either a simple\\nsequence of keywords or the identifier of a full document found in previous\\nsearches that is considered of interest). We consider the case of a textual\\ndatabase made of semi-structured documents. Each field, in turns, is modelled\\nwith a specific vector space. The problem is more complex when we also allow\\neach such vector space to have an associated user-defined dynamic weight that\\ninfluences its contribution to the overall dynamic aggregated and weighted\\nsimilarity. This dynamic problem has been tackled in a recent paper by\\nSingitham et al. in in VLDB 2004. Their proposed solution, which we take as\\nbaseline, is a variant of the cluster-pruning technique that has the potential\\nfor scaling to very large corpora of documents, and is far more efficient than\\nthe naive exhaustive search. We devise an alternative way of embedding weights\\nin the data structure, coupled with a non-trivial application of a clustering\\nalgorithm based on the furthest point first heuristic for the metric k-center\\nproblem. The validity of our approach is demonstrated experimentally by showing\\nsignificant performance improvements over the scheme proposed in Singitham et\\nal. in VLDB 2004. We improve significantly tradeoffs between query time and\\noutput quality with respect to the baseline method in Singitham et al. in in\\nVLDB 2004, and also with respect to a novel method by Chierichetti et al. to\\nappear in ACM PODS 2007. We also speed up the pre-processing time by a factor\\nat least thirty.\\n')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Modern text retrieval systems often provide a similarity search utility, that\n",
      "allows the user to find efficiently a fixed number k of documents in the data\n",
      "set that are most similar to a given query (here a query is either a simple\n",
      "sequence of keywords or the identifier of a full document found in previous\n",
      "searches that is considered of interest). We consider the case of a textual\n",
      "database made of semi-structured documents. Each field, in turns, is modelled\n",
      "with a specific vector space. The problem is more complex when we also allow\n",
      "each such vector space to have an associated user-defined dynamic weight that\n",
      "influences its contribution to the overall dynamic aggregated and weighted\n",
      "similarity. This dynamic problem has been tackled in a recent paper by\n",
      "Singitham et al. in in VLDB 2004. Their proposed solution, which we take as\n",
      "baseline, is a variant of the cluster-pruning technique that has the potential\n",
      "for scaling to very large corpora of documents, and is far more efficient than\n",
      "the naive exhaustive search. We devise an alternative way of embedding weights\n",
      "in the data structure, coupled with a non-trivial application of a clustering\n",
      "algorithm based on the furthest point first heuristic for the metric k-center\n",
      "problem. The validity of our approach is demonstrated experimentally by showing\n",
      "significant performance improvements over the scheme proposed in Singitham et\n",
      "al. in VLDB 2004. We improve significantly tradeoffs between query time and\n",
      "output quality with respect to the baseline method in Singitham et al. in in\n",
      "VLDB 2004, and also with respect to a novel method by Chierichetti et al. to\n",
      "appear in ACM PODS 2007. We also speed up the pre-processing time by a factor\n",
      "at least thirty.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(r[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dictionary update sequence element #0 has length 1; 2 is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 27\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# metadata_field_info = [\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     AttributeInfo(\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#         name=\"genre\",\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# ]\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# document_content_description = \"Brief summary of a movie\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43mSelfQueryRetriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_llm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpage_content\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/langchain/retrievers/self_query/base.py:225\u001b[0m, in \u001b[0;36mSelfQueryRetriever.from_llm\u001b[0;34m(cls, llm, vectorstore, document_contents, metadata_field_info, structured_query_translator, chain_kwargs, enable_limit, use_original_query, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallowed_operators\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m chain_kwargs\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m structured_query_translator\u001b[38;5;241m.\u001b[39mallowed_operators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    221\u001b[0m ):\n\u001b[1;32m    222\u001b[0m     chain_kwargs[\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallowed_operators\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m     ] \u001b[38;5;241m=\u001b[39m structured_query_translator\u001b[38;5;241m.\u001b[39mallowed_operators\n\u001b[0;32m--> 225\u001b[0m query_constructor \u001b[38;5;241m=\u001b[39m \u001b[43mload_query_constructor_runnable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocument_contents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata_field_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mchain_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    233\u001b[0m     query_constructor\u001b[38;5;241m=\u001b[39mquery_constructor,\n\u001b[1;32m    234\u001b[0m     vectorstore\u001b[38;5;241m=\u001b[39mvectorstore,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    238\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/langchain/chains/query_constructor/base.py:342\u001b[0m, in \u001b[0;36mload_query_constructor_runnable\u001b[0;34m(llm, document_contents, attribute_info, examples, allowed_comparators, allowed_operators, enable_limit, schema_prompt, fix_invalid, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_query_constructor_runnable\u001b[39m(\n\u001b[1;32m    310\u001b[0m     llm: BaseLanguageModel,\n\u001b[1;32m    311\u001b[0m     document_contents: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    321\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Runnable:\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;124;03m\"\"\"Load a query constructor runnable chain.\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m        A Runnable that can be used to construct queries.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[43mget_query_constructor_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocument_contents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattribute_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallowed_comparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_comparators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallowed_operators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_operators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m     allowed_attributes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ainfo \u001b[38;5;129;01min\u001b[39;00m attribute_info:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/langchain/chains/query_constructor/base.py:225\u001b[0m, in \u001b[0;36mget_query_constructor_prompt\u001b[0;34m(document_contents, attribute_info, examples, allowed_comparators, allowed_operators, enable_limit, schema_prompt, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m default_schema_prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    222\u001b[0m     SCHEMA_WITH_LIMIT_PROMPT \u001b[38;5;28;01mif\u001b[39;00m enable_limit \u001b[38;5;28;01melse\u001b[39;00m DEFAULT_SCHEMA_PROMPT\n\u001b[1;32m    223\u001b[0m )\n\u001b[1;32m    224\u001b[0m schema_prompt \u001b[38;5;241m=\u001b[39m schema_prompt \u001b[38;5;129;01mor\u001b[39;00m default_schema_prompt\n\u001b[0;32m--> 225\u001b[0m attribute_str \u001b[38;5;241m=\u001b[39m \u001b[43m_format_attribute_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattribute_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m schema \u001b[38;5;241m=\u001b[39m schema_prompt\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    227\u001b[0m     allowed_comparators\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(allowed_comparators),\n\u001b[1;32m    228\u001b[0m     allowed_operators\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(allowed_operators),\n\u001b[1;32m    229\u001b[0m )\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m examples \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(examples[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/langchain/chains/query_constructor/base.py:165\u001b[0m, in \u001b[0;36m_format_attribute_info\u001b[0;34m(info)\u001b[0m\n\u001b[1;32m    163\u001b[0m info_dicts \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m info:\n\u001b[0;32m--> 165\u001b[0m     i_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     info_dicts[i_dict\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)] \u001b[38;5;241m=\u001b[39m i_dict\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mdumps(info_dicts, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: dictionary update sequence element #0 has length 1; 2 is required"
     ]
    }
   ],
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "# metadata_field_info = [\n",
    "#     AttributeInfo(\n",
    "#         name=\"genre\",\n",
    "#         description=\"The genre of the movie\",\n",
    "#         type=\"string or list[string]\",\n",
    "#     ),\n",
    "#     AttributeInfo(\n",
    "#         name=\"year\",\n",
    "#         description=\"The year the movie was released\",\n",
    "#         type=\"integer\",\n",
    "#     ),\n",
    "#     AttributeInfo(\n",
    "#         name=\"director\",\n",
    "#         description=\"The name of the movie director\",\n",
    "#         type=\"string\",\n",
    "#     ),\n",
    "#     AttributeInfo(\n",
    "#         name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"\n",
    "#     ),\n",
    "# ]\n",
    "# document_content_description = \"Brief summary of a movie\"\n",
    "llm = OpenAI(temperature=0)\n",
    "# retriever = SelfQueryRetriever.from_llm(\n",
    "#     llm, vectorstore, 'page_content', 'metadata', verbose=True\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
